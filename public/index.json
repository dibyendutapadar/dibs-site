[{"content":"AI-Powered Email Processing System for a Fashion Retailer Turning chaotic inboxes into structured, automated order \u0026amp; inquiry workflows Retail operations look deceptively simple from the outside: customers email, staff respond, orders get booked, stock gets updated. Under the hood, itâ€™s usually an unstructured messâ€”especially for small or mid-size fashion brands that havenâ€™t fully automated their digital operations. The result is slow responses, lost orders, inconsistent inventory updates, and frustrated customers.\nThis project is a practical proof-of-concept that shows how LLMs can be deployed as real workers in this workflow. Not abstract magic. Actual operational logic.\nThe goal: Automatically read incoming emails, understand whether they are order requests or product inquiries, extract structured data, check stock, update inventory, and generate responsesâ€”end to end.\nEverything runs through a modular chain of LLM-based â€œmicro-agents,â€ each responsible for a small, verifiable task. This keeps the system interpretable instead of becoming a mysterious black box.\nRepo:\nBusiness Context: Why This Problem Exists A fashion retailer receives two types of recurring emails:\nâ€œDo you have this in size M?â€\nâ€” product inquiries\nâ€œI want to order 2 beige linen shirts.â€\nâ€” order requests\nThese land in a common inbox. Humans spend hours manually:\nreading each email\ndetermining intent\nchecking product catalog and stock\npreparing responses\nadjusting inventory\nlogging orders manually in sheets / db\nThe friction multiplies with scale.\nThe mistakes multiply even faster.\nAn LLM-based system solves exactly these bottlenecks:\nno missed orders\nreal-time stock updates\nconsistent responses\nstructured logs for auditing\nscalability without hiring more staff\nThe system is not meant to be a chatbot. It is meant to be an intelligent back-office workerâ€”fast, predictable, and fully auditable.\nTechnical Overview: How the System Works The design intentionally avoids monolithic â€œone giant promptâ€ architectures. Instead, each function is a narrow expertâ€”an independent agent.\nProcessing happens sequentially, not in batches, to maintain inventory correctness. When two emails request the same product, sequential order ensures one stock update happens before the next evaluation.\nEverything flows through a deterministic pipeline:\nflowchart TD A[llm_classify_email] --\u003e B[email-classification log] B --\u003e C{Is Order Request?} %% Order Request Path C --\u003e|Yes| D[llm_extract_order_items] D --\u003e E[process_order_requests_pipeline] E --\u003e F[llm_generate_order_response] F --\u003e G[order-response log] %% Product Inquiry Path C --\u003e|No, Product Inquiry| H[answer_inquiry_with_stock - RAG and stock lookup] H --\u003e I[inquiry-response log] %% Final Step G --\u003e J[Write all logs] I --\u003e J[Write all logs] This structure makes the system easy to reason about, easy to debug, and easy to extend.\nPotential Future Extensions Multi-store inventory sync If stock is distributed across warehouses. Price negotiation automation Common in boutique fashion retail. CRM integration Tag customers by intent, lifecycle, and purchase history. Predictive insights Incoming email patterns â†’ demand forecasting (email-driven signals are underutilized gold) Full order booking Push confirmed orders directly into ERP or Shopify. The pipeline already supports extension because each agent is isolated.\n","permalink":"https://dibyendupm.netlify.app/projects/ai-powered-email-processing-system-for-a-fashion-retailer/","summary":"Turning chaotic inboxes into structured, automated order \u0026amp; inquiry workflows","title":"AI-Powered Email Processing System for a Fashion Retailer"},{"content":"The project enables chatting and extracting information and insights from internal documents using a locally deployed LLM.\nKey Features\nUses Retrieval-Augmented Generation (RAG) and LangChain techniques Supports various document formats Provides accurate and context-aware responses based on document content ğŸ’¡ Goal: Facilitate efficient and intelligent information retrieval from internal documents.\nTechnologies Used: LLM, RAG, LangChain, Streamlit, Ollama\nğŸ”— GitHub ğŸ“ Read on LinkedIn ","permalink":"https://dibyendupm.netlify.app/projects/chat-with-local-documents/","summary":"Enables intelligent chat and data extraction from internal documents using a locally deployed LLM with RAG and LangChain.","title":"Chat with Local Documents"},{"content":"AI Travel Agent with crewAI and Ollama Traditional OTAs like MakeMyTrip and Booking limit users to fixed filters.\nThis project offers an unrestricted AI search experience based on user intent. An unrestricted AI-powered search experience driven by user intent.\nğŸ”‘ Key Features â€¢ Personalized Search â€” Users describe their travel needs naturally.\nExample: â€œA secluded stay by a riverside within 200 km from Bangalore with Wi-Fi and parking.â€\nâ€¢ AI-Powered Recommendations â€” Specialized agents interpret intent and fetch the most relevant options.\nâ€¢ Detailed Itineraries â€” Automatically generated using dedicated itinerary agents for end-to-end trip planning.\nğŸ’¡ How It Works Agent Role Description ğŸ§© Intent Mapper Agent ğŸ§  Understanding Extracts key details and user preferences from natural language queries. ğŸ” Finder Agent ğŸŒ Discovery Searches for destinations, stays, or activities that best match the extracted intent. ğŸª„ Formatter Agent âœ¨ Presentation Structures and refines results into a clean, readable format. ğŸ—ºï¸ Itinerary Agent ğŸ§³ Planning Builds a complete travel itinerary, including suggestions and timelines. â„¹ï¸ Technologies Used\nOllama Â· CrewAI Â· Streamlit\nResources\nğŸ”— GitHub ğŸ“ Read on LinkedIn ","permalink":"https://dibyendupm.netlify.app/projects/ai-travel-agent-for-stay-and-itinerary-planning/","summary":"AI-driven travel planner that provides unrestricted, natural-language-based search and itinerary generation.","title":"AI Travel Agent for Stay and Itinerary Planning"},{"content":"AI Agent to analyze your snaps. How about a crew of AI agents who can sift through your snaps, pick the absolute best ones, and even whip up the perfect Instagram captions? Say goodbye to the endless selection and caption conundrums. With AI agents, we are stepping into the future of AI-powered creativity, where your snaps are transformed into Instagram hits without breaking a sweat.\nThe \u0026ldquo;Insta Influencer\u0026rdquo; Image Analyzer This nifty app is like having your very own Instagram manager on speed dial. Simply upload a bunch of images, and let the AI do the heavy lifting. It doesnâ€™t just pick the best photo; it goes a step further by crafting a caption thatâ€™s not only on-trend but tailored to the vibe of your image. How? By harnessing the power of advanced AI models that understands images and what makes a post pop on Instagram.\nğŸ”— Check out the Git repo here: https://github.com/dibyendutapadar/ai-agent-image-analyzer Demo: I provided the app some pics from Goa trip to analyze from. The response was quite astonishing form 8b models run on local. Notice how detailed the image descriptions are.\nThe Tech That Makes It All Happen Large Language Models (LLMs) At the heart of this magic is obviously LLMs (Large Language Models). LLMs have been game-changers in making our interactions with technology more natural, almost like chatting with a super-smart friend.\nLLaMA and LLAVA Now, letâ€™s talk about two key players: LLaMA (Large Language Model Accelerated) and LLAVA (Large Language Vision Agent). LLaMA is one of your go-to LLM for processing text, while LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding.\nTogether, theyâ€™re the dynamic duo that enables this app to seamlessly juggle both text and images.\nI have used 8b models of both, but if you have access to superior computing power (read GPU) you can use larger models as well\nAI Agents and Crew AI Hereâ€™s where it gets even coolerâ€”AI agents. These are autonomous helpers that handle tasks for you. In our app, we use CrewAI to coordinate these agents, making sure everything runs smoothly. Itâ€™s like having a team of experts working behind the scenes to ensure your photos and captions are on point.\nHow It All Comes Together So, how exactly we select from photos into Instagram-worthy posts? Letâ€™s break it down:\nUpload Your Photos: Start by uploading your imagesâ€”whether theyâ€™re in PNG, JPG, or JPEG format. AI Image Analysis: The magic begins as LLAVA gets to work, analyzing your images to extract detailed descriptions. Itâ€™s like having an art critic and a storyteller rolled into one, interpreting each photo. Crafting the Perfect Caption: Armed with these descriptions the agent then picks the best image and writes a caption thatâ€™s primed for maximum engagement. It considers everything from trending hashtags to current events. AI Agent in Action: Crew AI coordinates the process, ensuring that the agentâ€™s decisions are spot on. The agent doesnâ€™t just pick a photo and write a caption; it does so with a clear strategy in mind, maximizing your postâ€™s potential to go viral. Your Ready-Made Instagram Post: Finally, the app presents the results in a clean, easy-to-use format. You get a detailed breakdown of all your photos, the chosen winner with an explanation, and a caption ready to be copied and pasted straight into Instagram. And the best part about this,\nAll this is achieved without any need to train the model on own data.\nGone are the days of scrambling to gather massive datasets just to get started. These pre-trained models give you a serious head start. Sure, you can fine-tune them with your specific data to make them even better, but as you can see from the results, theyâ€™re already delivering impressive outcomes right out of the box.\nWhat\u0026rsquo;s the big deal? ChatGPT can already do this. Of course, it canâ€”but thereâ€™s a catch. While GPT-4 and its image processing capabilities can handle similar tasks, these features often come with a price tag.\nPlus, our app is a playground for these ideas, offering a fun, user-friendly way to explore what AI can do with your images. Now, imagine scaling this up for industrial use cases. Organizations can employ similar methodologies to tackle specific challenges unique to their operationsâ€”without the worry of sharing sensitive information with a third-party service like ChatGPT.\nIn-house AI solutions provide a tailored approach, ensuring privacy and control over proprietary data.\nBeyond a toy app to Organizational use cases Below are some industry use cases where images are too sensitive and confidential to be exposed to third part service provider. Getting LLMs deployed on premise, can help maintian the secrecy and getting the job done.\nHealthTech Medical Imaging: Assist in diagnosing conditions from X-rays to MRIs. Lets see this in action. It was fascinating to see how much can be achieved without any fine tuning from a 8b vision model and a 8b text model with 30 lines of code on a personal laptop\nEdTech Grading Exams: Automate grading for handwritten exams, ensuring fairness and speed. (I have a hunch that with the democratisation of GenAI, handwritten exams are going to come back. For EdTech enthusiasts, you can read this study on the effect of GenAI on education) Let\u0026rsquo;s see how an untuned model can provide a head start for evaluation of answer scripts.\nIt can also be used in other sectors where information is absolutely confidential\nFinTech Customer Verification: Automate document verification with image analysis. Insurance Claims Processing: Quickly assess damages with image evaluation. Technologies Used: LLaMA, LLaVA, CrewAI, Streamlit\nğŸ”— GitHub ğŸ“ Read on LinkedIn ","permalink":"https://dibyendupm.netlify.app/projects/image-analysis-with-llava-and-llama/","summary":"Uses multimodal LLMs for domain-specific image understanding in marketing, education, and healthcare.","title":"Image Analysis with LLaVA and LLaMA"},{"content":"ğŸŒŸ ğ—–ğ—®ğ—» ğ˜„ğ—² ğ—°ğ—¿ğ—²ğ—®ğ˜ğ—² ğ—®ğ—» ğ—®ğ—±ğ—®ğ—½ğ˜ğ—¶ğ˜ƒğ—² ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—”ğ—½ğ—½ ğ˜‚ğ˜€ğ—¶ğ—»ğ—´ ğ—Ÿğ—Ÿğ—  ğ˜„ğ—¶ğ˜ğ—µğ—¼ğ˜‚ğ˜ ğ—® ğ—¾ğ˜‚ğ—²ğ˜€ğ˜ğ—¶ğ—¼ğ—» ğ—®ğ—»ğ˜€ğ˜„ğ—²ğ—¿ ğ—±ğ—®ğ˜ğ—®ğ˜€ğ—²ğ˜? ğŸ¤” I gave it a try! ğŸš€\nI built an app on Streamlit utilizing LlamaIndex . It takes in key information fromt he user , wraps it in a prompt, and uses Groq inference API for a small ğ—Ÿğ—Ÿğ—  (ğ—¹ğ—¹ğ—®ğ—ºğ—®ğŸ¯.ğŸ­-ğŸ´ğ—¯-ğ—¶ğ—»ğ˜€ğ˜ğ—®ğ—»ğ˜) to generate responses. By leveraging ğ—½ğ˜†ğ—±ğ—®ğ—»ğ˜ğ—¶ğ—°, we generate structured output in format that can be made as a multiple choice question, and the in-between data storage plus proficiency calculations are handled by ğ—¦ğ—¤ğ—Ÿğ—¶ğ˜ğ—². Based on the calculation, after each answer, the LLM is prompted with the difficulty level of the next question to be generated.\nğŸ”— You can try out the app here: https://lnkd.in/gtXUHWMp ğŸ’¡ ğ—™ğ—¶ğ—»ğ—±ğ—¶ğ—»ğ—´ğ˜€: The answer is both yes and no! We can jumpstart by using the data the LLM was trained on. Even a small model does a fair job, but limited and un-curated knowledge base hampers the experience.\nHowever, this can be tackled with ğ—¥ğ—”ğ—š ğ˜ğ—²ğ—°ğ—µğ—»ğ—¶ğ—¾ğ˜‚ğ—²ğ˜€. Where the exact contextual data can be retrieved from documents (books, PDFs, databases, PPTs, Videos) and then augmented by using an LLM. Particularly Graph RAG is showing promising potential for these kind of knowledge driven problem\nğŸ¤” ğ—£ğ—¼ğ˜€ğ˜€ğ—¶ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ—¶ğ—²ğ˜€: ğŸ¯ ğ—”ğ—±ğ—®ğ—½ğ˜ğ—¶ğ˜ƒğ—² ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´: Generates questions matching a learner\u0026rsquo;s proficiency. Using knowledge graph the system can even be made to understand pre-grade learning gaps of the learner.\nğŸ“š ğ——ğ˜†ğ—»ğ—®ğ—ºğ—¶ğ—° ğ—–ğ—¼ğ—»ğ˜ğ—²ğ—»ğ˜: Creates content tailored to individual learning gaps (text, image, audio, video via multimodal LLMs). Should be an improvement over theÂ long MOOCs, which starts and ends at the same level and follows the same path for every learner.\nğŸ§  ğ—–ğ—¼ğ—»ğ˜ğ—²ğ˜…ğ˜ğ˜‚ğ—®ğ—¹ ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´: Customizes content to the learner\u0026rsquo;s interests, like teaching math to a cricket enthusiast student using cricket examples. And the best part, we don\u0026rsquo;t need to have curated datasets to do that, it can be generated. ğŸâš¾\nAI\u0026rsquo;s (Specifically GenAI\u0026rsquo;s) impact on education is being debated heavily, and rightly so. But can we ignore its potential? I donâ€™t think we can! ğŸ¤–âœ¨\nTechnologies Used: Python, Groq, LlamaIndex, Llama 3.1-8B, SQLite, Streamlit, Pydantic\nğŸ”— GitHub ğŸ“ Read on LinkedIn ğŸ“± App Link ","permalink":"https://dibyendupm.netlify.app/projects/adaptive-learning-without-question-answer-dataset/","summary":"Generates adaptive learning assessments dynamically using GenAI and proficiency tracking.","title":"Adaptive Learning without Question-Answer Dataset"},{"content":"An AI-powered digital platform designed for edTech organizations, enabling the digital capture of pen-and-paper test transcripts and scores. This facilitates the enhancement of student learning outcomes by allowing for the personalization of educational offerings.\nMy Role - 2021, Product Manager, Byjus -\nI worked with our multidisciplinary team to take AssessEd from implementation to growth, maturity and retirement (replacing with an enhaced platform). I conducted research, user interviews, managed onboarding, oversaw AI training, and worked closely with the CEO, product designer and engineering managers to enhance, mature and integrate the system with multiple existing systems.\nIntroduction (Origin Story) The COVID-19 pandemic brought about a seismic shift in the education sector, propelling online learning to the forefront. While this transition offered several advantages, it also posed challenges, particularly concerning traditional pen and paper tests. Education boards were hesitant to abandon the tried-and-tested offline mode of assessments due to its numerous benefits. In response to this dilemma, a groundbreaking test-taking platform was developed, seamlessly merging the advantages of both online and offline assessment methods.\nThe Challenge: Problem Statement During the COVID-19 pandemic, the online education sector experienced an unprecedented boom, leading to a significant decrease in offline interactions. However, pen and paper tests continued to hold importance due to the following four notable benefits:\nAuthenticity and Security: Pen and paper tests provide a tangible experience, ensuring the authenticity of the examination process. With controlled environments and invigilation, the integrity of the assessments remains intact.\nPhysical Interaction: Offline tests foster face-to-face interactions between teachers and students, facilitating a more personal and engaging educational experience. Non-verbal cues and direct communication enhance the learning process.\nCognitive Retention: Research suggests that taking notes by hand improves information retention and understanding. The act of writing on paper helps students synthesize knowledge, boosting memory and comprehension.\nEquality and Accessibility: Pen and paper tests ensure equal access for all students, regardless of their socioeconomic background or internet availability. They level the playing field, minimizing the disadvantages faced by students lacking reliable internet connections.\nThe Solution To address the challenges faced in conducting pen and paper tests during the online education boom, a comprehensive test-taking platform was developed. This innovative solution enabled teachers to conduct assessments and allowed students to attempt tests using both online and offline modes, combining the best of both worlds.\nThe Product features: The test-taking platform introduced a dual interface that catered to the needs of both teachers and students. Here\u0026rsquo;s an overview of the features and benefits it offered:\nAuto-creation of Assessments: Teachers can easily create assessments within the platform, with smart-assist by the system specific to the students.\nSeamless Test Distribution: Teachers could distribute assessments digitally or in physical format, depending on the mode of interaction. Online distribution made it convenient for students to access assessments remotely, while physical copies catered to offline classroom scenarios.\nHybrid Answer Sheet Upload: Students had the freedom to answer questions on physical answer sheets or within the platform\u0026rsquo;s digital interface. For Homeworks, students scanned their answer sheets through app and uploaded them, while teachers collected and scanned physical answer sheets in an offline test setting.\nAI-Driven Image Server: The system employed an AI-driven image server to read, segment, and evaluate the answers within minutes. This automation streamlined the evaluation process, making it swift, efficient, and effortless.\nInsights for Personalized Learning: By digitizing answer scripts and scores, the platform gathered valuable insights. These insights were fed into a student data-lake, enabling the creation of personalized learning models and assessments. Students could benefit from tailored educational content, catering to their unique needs, and enhancing their learning outcomes.\nMetrics 10k+ personalized offline assessments are conducted each week for 200k+students. More practice leads to better outcome\nThe collective outcome of the students average scores improved by 7 percentage points over an academic year\nThe time taken to conduct, evaluate and publish the evaluated papers were made to 2.5 days by ingesting technological benefits in the offline test taking medium\n","permalink":"https://dibyendupm.netlify.app/blog/byjus-assessed/","summary":"\u003cp\u003e\u003cem\u003eAn AI-powered digital platform designed for edTech organizations, enabling the digital capture of pen-and-paper test transcripts and scores. This facilitates the enhancement of student learning outcomes by allowing for the personalization of educational offerings.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ree\" loading=\"lazy\" src=\"https://static.wixstatic.com/media/f3d706_a2c9e1602581406a8b5f4beebc0ee438~mv2.png/v1/fill/w_1199,h_749,al_c,q_90,enc_avif,quality_auto/f3d706_a2c9e1602581406a8b5f4beebc0ee438~mv2.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"my-role\"\u003e\u003cstrong\u003eMy Role\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e- 2021, Product Manager, Byjus -\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eI worked with our multidisciplinary team to take AssessEd from implementation to growth, maturity and retirement (replacing with an enhaced platform). I conducted research, user interviews, managed onboarding, oversaw AI training, and worked closely with the CEO, product designer and engineering managers to enhance, mature and integrate the system with multiple existing systems.\u003c/p\u003e","title":"AssessEd - Bridging gap between the digital EdTech world and Offline Assessments."},{"content":"Origin Story In 2016, despite holding over 50% of the market share, the unauthorized car repair workshops relied on manual pen and paper processes. They failed to follow the digital trend, missing out on benefits that the taxis and food delivery industry was gaining. As a consequence, they were unable to provide their customers with an improved and transparent experience, and they also failed to optimize their daily operations by harnessing the power of technology.\nMy Role As the sole product manager, I led the complete product lifecycle, beginning with ideation, conducting user research, facilitating design sprints, conducting initial user interaction tests with designs, developing the minimum viable product (MVP), and ultimately overseeing the full-fledged rollout, iterating throughout multiple sprints.\nThe Product DearO (Digitally enhanced automotive repair operations system) was ideated to transform the automobile service industry, making day-to-day workshop operations simpler, faster, and smarter than ever before. With its comprehensive suite of features, DearO streamlines workflow, enhances customer communication, and optimizes inventory management, revolutionizing the way a small-medium automotive service businesses operated.\nAdvantages and Features: Mobile-Friendly and Cost-Effective: DearO is a mobile-friendly solution that requires no installation or setup costs, allowing businesses to quickly adopt and integrate the system into their operations.\nCloud-Based Security: With a cloud-based infrastructure, DearO ensures high-level security for workshop data, protecting sensitive information and providing peace of mind.\nPreemptive Damage and Belongings Management: DearO enables workshops to note and share scratches, damages, and personal belongings in vehicles with customers in advance, minimizing disputes and enhancing transparency.\nGST-Enabled Invoicing: DearO features a smart, GST-ready invoicing system that simplifies and accelerates the billing process, saving time and ensuring compliance.\nSeamless Communication: Share invoices and job cards with customers via WhatsApp or email, providing convenience and flexibility to suit their preferences.\nSwift Digital Job Card Creation: Create digital job cards in a matter of seconds, reducing paperwork and improving efficiency.\nCentralized Dashboard: Monitor all job cards and invoices from a user-friendly dashboard, ensuring streamlined operations and comprehensive oversight.\nReal-Time Customer Updates: DearO enhances customer satisfaction by providing automatic real-time status updates through a personalized web portal, keeping customers informed and engaged.\nSmart Labor and Parts Pricing: Benefit from smart search functionality that suggests labor and parts pricing based on the make and model of cars and bikes, simplifying cost estimation.\nAuto-Suggestion and Service Schedules: DearO offers auto-suggestions for jobs based on vehicle history and inspection, as well as parts item recommendations aligned with manufacturers\u0026rsquo; recommended service schedules.\nIMPACT Adopted by 1k paid users within a year of launch. The users found the following benefits from adopting the product\nIncreased Business Revenue: Enhance revenue streams with features such as vehicle inspection reports and built-in service schedules that facilitate upselling and efficient service planning.\nImproved Profitability: Avoid time and costs associated with handling customer disputes related to fuel theft, item theft, unwanted jobs, damages, and scratches allegations.\nElevated Customer Experience: Provide automated real-time service updates, vehicle inventory reports, job card details, and invoice statuses, elevating customer satisfaction and loyalty.\nEnhanced Business Monitoring: Leverage end-of-day reports on job cards and invoicing to gain insights and optimize operations. Manage inventory effortlessly through a simple purchase system and auto-updates on parts invoicing.\nApp Link ","permalink":"https://dibyendupm.netlify.app/blog/dearo-wms/","summary":"\u003ch2 id=\"origin-story\"\u003eOrigin Story\u003c/h2\u003e\n\u003cp\u003eIn 2016, despite holding over 50% of the market share, the unauthorized car repair workshops relied on manual pen and paper processes. They failed to follow the digital trend, missing out on benefits that the taxis and food delivery industry was gaining. As a consequence, they were unable to provide their customers with an improved and transparent experience, and they also failed to optimize their daily operations by harnessing the power of technology.\u003c/p\u003e","title":"DearO - the simplest and smartest Automobile Workshop Management system"},{"content":"\nThe Product Khan for Educators is a powerful tool built on top of Khan Academy\u0026rsquo;s world-renowned educational content, designed specifically for teachers. Khan for Educators revolutionizes the teaching and learning experience by providing a comprehensive set of tools for tutors to create classes, add students, assign videos and assessments, and track individual progress and mastery levels at a concept level.\nCore Features Class Creation: Teachers can effortlessly create classes, organizing students and content in a streamlined manner.\nIndividual Student Logins: Each student receives a personalized login, allowing them to access assigned materials and track their progress.\nAssignments and Assessments: From the teacher\u0026rsquo;s tools section, educators can easily assign videos and assessments to students, tailoring the learning experience to meet their unique needs.\nProgress Tracking: Khan for Educators provides detailed insights into student scores, engagement, performance, and mastery on individual concepts. This information enables teachers to identify areas of improvement and deliver personalized interventions.\nMy Role In my capacity as a Product Manager, I was responsible for optimizing and productising the base Khan for Educators model to align with the specific requirements of the Indian education ecosystem. This involved developing supplementary products and features to facilitate the adoption of the solution by state government education boards, enabling them to seamlessly implement it in public schools across the state.\nIn lieu of Khan Academy\u0026rsquo;s vision, \u0026ldquo;to provide a free world-class education for anyone, anywhere\u0026rdquo;, we made the strategic decision to concentrate on public schools, an untapped market with vast potential. Meanwhile, the private and paid education sector was becoming highly competitive, crowded with numerous EdTech organizations, resulting in a saturated market, often referred to as a red ocean.\nHowever, introducing our offerings to public schools through state education departments proved to be a challenging endeavor. Nevertheless, we persevered and successfully maneuvered through those obstacles along the way.\nChallenges Solutions Most public school teachers lacked the technical proficiency to self-adopt a tech driven platform 1. Built Teacher training modules, on self completion automatic certifications will be provided\n2. Built Whatsapp based support chatbot to help teachers at each step of operation and to communicate with teachers to instill confidence Creating profiles of students, teachers across thousands of schools was a challenge. The existing system supported creation of profiles one-by-one at an individual level, and this method would have called for too much operational overhead. Developed a complete rostering system that incorporates UDISE and state education board data, freeing teachers of all operational work and to concentrate on what they do best- teaching. There was a lack of momentum to adopt a new system from the start. Introduced and executed LearnStorm , a campaign where completion of learning tasks is gamified, and prizes are awarded to the class with most points. over 40,000 teachers across India participated with their classes of students The Government state education board required an overview of engagement and outcome of students at multiple levels Took advantage of GCP\u0026rsquo;s integration with Google Data Studio and built actionable dashboards for the state govt education department that enabled them to track engagement and impact on real time basis. Impact Growth The entire package of solution was adopted by multiple state governments, owing to which the Monthly Active Users of Khan Academy in India grew from 50,000 to 5 lakh in one year.\nLearning Outcome Punjab - the highest adopter of the solution achieved Rank 1 amongst all states in the National Achievement Survey 2021 ","permalink":"https://dibyendupm.netlify.app/blog/khan-for-tutors/","summary":"\u003cp\u003e\u003cimg alt=\"ree\" loading=\"lazy\" src=\"https://static.wixstatic.com/media/f3d706_352ca2ef376a446f9a84a7d197387b11~mv2.png/v1/fill/w_1216,h_554,al_c,q_90,enc_avif,quality_auto/f3d706_352ca2ef376a446f9a84a7d197387b11~mv2.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"the-product\"\u003eThe Product\u003c/h2\u003e\n\u003cp\u003eKhan for Educators is a powerful tool built on top of Khan Academy\u0026rsquo;s world-renowned educational content, designed specifically for teachers. Khan for Educators revolutionizes the teaching and learning experience by providing a comprehensive set of tools for tutors to create classes, add students, assign videos and assessments, and track individual progress and mastery levels at a concept level.\u003c/p\u003e\n\u003ch2 id=\"core-features\"\u003eCore Features\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eClass Creation: Teachers can effortlessly create classes, organizing students and content in a streamlined manner.\u003c/p\u003e","title":"Khan Academy for Tutors"},{"content":"In the ever-evolving landscape of education, the integration of technology has become paramount. My journey as a product manager at Byju\u0026rsquo;s, a leading ed-tech company, reflects this transformation. I led the development of an automation tool that revolutionized the traditional methods of test creation and assessment, aligning perfectly with the modern educational needs.\nMy Role: As a product manager, my role was multifaceted. I was not only the brainchild behind this initiative but also the driving force in its execution. My responsibility encompassed everything from conceptualization to overseeing the development and implementation of the tool.\nThe Challenge: Overcoming Manual Overheads and Generic Assessments The initial challenge was evident. Teachers within our system were burdened with the task of manually creating tests, quizzes, and assessments. This process was time-consuming, labor-intensive, and lacked personalization for individual learners. The need for a system that could alleviate this overhead and cater to the unique learning paths of students was clear.\nThe Solution: A Seamless Integration of Systems To address this, I led the development of an automatic test builder. This innovative tool bridged various systems - Learning Management System (LMS), Content Management System (CMS), Quiz modules, and the Learner App. It functioned by selecting questions based on a pre-defined template and the individual skill levels of students, creating a tailor-made assessment.\nProduct Features: Personalization and Flexibility Personalized Homework:Â After each class, the tool generated homework tailored to the topics covered, directly assigned to the students who attended the class.\nMonthly Tests:Â It created monthly tests for batches, focusing on the topics taught during that month.\nAdaptable Assessment Modes:Â The assessments could be set in either online or offline modes, offering flexibility in delivery and accessibility.\nMetrics and Results: A Leap in Operational Efficiency The most significant achievement of this tool was the drastic reduction in operational manhours - a cut down of over 3000 hours per week. This efficiency not only freed up valuable time for educators but also ensured that assessments were more aligned with the individual learning trajectories of students, resulting in ~20 percent point improvement in attempt rates and ~7 percent point improvement in student outcome.\n","permalink":"https://dibyendupm.netlify.app/blog/automated-assessments/","summary":"\u003cp\u003e\u003cem\u003eIn the ever-evolving landscape of education, the integration of technology has become paramount. My journey as a product manager at Byju\u0026rsquo;s, a leading ed-tech company, reflects this transformation. I led the development of an automation tool that revolutionized the traditional methods of test creation and assessment, aligning perfectly with the modern educational needs.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ree\" loading=\"lazy\" src=\"https://static.wixstatic.com/media/f3d706_48f46023467c490fa5aa7e25517a838d~mv2.png/v1/fill/w_1480,h_846,al_c,q_90,usm_0.66_1.00_0.01,enc_avif,quality_auto/f3d706_48f46023467c490fa5aa7e25517a838d~mv2.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"my-role\"\u003eMy Role:\u003c/h2\u003e\n\u003cp\u003eAs a product manager, my role was multifaceted. I was not only the brainchild behind this initiative but also the driving force in its execution. My responsibility encompassed everything from conceptualization to overseeing the development and implementation of the tool.\u003c/p\u003e","title":"Revolutionizing Education with Automated Assessment - A Journey in Innovation in Byjus"},{"content":"A Streamlit app for demand forecasting with an intuitive, interactive interface. ğŸ“± App Link Key Features\nUses SARIMAX and Holt-Winters methods Allows live parameter configuration Provides real-time visualizations This app allows users to upload time series data and forecast using ARIMA and Holt-Winters (Triple Exponential Smoothing) methods. Navigate to the Forecast page to get started.\nHolt-Winters Triple Exponential Smoothing Holt-Winters Triple Exponential Smoothing, also known as Holt-Winters Method, is used for forecasting time series data that exhibits both trend and seasonality. The model requires you to set values for trend, seasonal, and seasonal_periods. Hereâ€™s a guide on how to determine these values:\nUnderstanding the Parameters: Trend (trend): This parameter indicates whether a trend component is included in the model. It can be: 'add'Â (additive): When the trend is expected to increase or decrease by a constant amount. 'mul'Â (multiplicative): When the trend increases or decreases by a percentage or ratio. None: When there is no trend. Seasonal (seasonal): This parameter indicates whether a seasonal component is included in the model. It can be: 'add'Â (additive): When seasonal variations are roughly constant over time. 'mul'Â (multiplicative): When seasonal variations change proportionally to the level of the time series. None: When there is no seasonality. Seasonal Periods (seasonal_periods): This parameter indicates the length of the seasonality cycle (e.g., 12 for monthly data with annual seasonality). Selecting the Parameters: a. Identify Trend and Seasonality: Visual Inspection: Plot your time series data. Look for patterns in the data: A consistent upward or downward slope suggests a trend. Repeating patterns at regular intervals suggest seasonality. Statistical Tests: Use autocorrelation plots (ACF) and partial autocorrelation plots (PACF) to identify seasonality. Significant spikes at lags corresponding to the seasonal period can indicate seasonality. b. Determine Seasonal Periods: Domain Knowledge: Use domain knowledge to identify the seasonal cycle. For instance, monthly data often has an annual seasonality period of 12 months. Autocorrelation: Significant autocorrelations at specific lags can help identify the seasonal period. c. Choosing Trend and Seasonal Types: Additive vs. Multiplicative: Use additive ('add') if the seasonal variations are roughly constant over time (the difference between high and low seasonality periods is constant). Use multiplicative ('mul') if the seasonal variations change proportionally with the level of the series (the percentage change is constant). SARIMAX Model SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors) is an extension of the ARIMA model that supports both seasonality and exogenous variables. It is used for forecasting time series data. The model parameters need to be carefully chosen to fit the data well. Hereâ€™s a guide on understanding and selecting these parameters:\nUnderstanding the Parameters: Non-Seasonal Components: p: The number of lag observations included in the model (autoregressive part). d: The number of times that the raw observations are differenced (integrated part). q: The size of the moving average window. Seasonal Components: P: The number of lag observations in the seasonal model (seasonal autoregressive part). D: The number of times that the seasonal differences are applied (seasonal integrated part). Q: The size of the moving average window in the seasonal model. m: The number of time steps for a single seasonal period. Exogenous Variables (X): These are additional variables that can be included in the model to provide more information that might affect the time series. Selecting the Parameters: a. Identify Non-Seasonal Parameters (p, d, q):\nVisual Inspection: Plot your time series data to look for trends and seasonality. ACF and PACF Plots: ACF (Autocorrelation Function): Helps in identifying the number of MA (q) terms. Significant spikes outside the confidence interval suggest the lag values. PACF (Partial Autocorrelation Function): Helps in identifying the number of AR (p) terms. Significant spikes outside the confidence interval suggest the lag values. Differencing: If the time series is non-stationary, apply differencing and observe the ACF and PACF plots again. Differencing helps to stabilize the mean of the time series by removing changes in the level of a time series, thereby eliminating (or reducing) trend and seasonality. b. Identify Seasonal Parameters (P, D, Q, m):\nSeasonal Differencing: If seasonality is present, seasonal differencing may be necessary. Seasonal ACF and PACF: Look at the ACF and PACF plots of the seasonally differenced series to identify seasonal AR (P) and MA (Q) terms. The seasonal period (m) should be known from the data (e.g., m = 12 for monthly data with yearly seasonality). c. Combining the Parameters:\nUse the identified non-seasonal and seasonal parameters to build the SARIMAX model. Exogenous Variables: Include any relevant external variables (X) if they are believed to influence the time series. Technologies Used: SARIMAX, Holt-Winters, Python, Streamlit\nğŸ”— GitHub ","permalink":"https://dibyendupm.netlify.app/projects/time-series-forecasting-app/","summary":"Interactive forecasting app using SARIMAX and Holt-Winters models with real-time visualizations.","title":"Time Series Forecasting App"},{"content":"An Experiment to disguise Open Source LLM as a Hotel Bookings Agent!! TL;DR Harnessing the power of open-source LLMs like Llama 3.1, I\u0026rsquo;ve tried to create a chatbot that simplifies hotel bookings, using \u0026ldquo;llama-3.1-8b-instant\u0026rdquo; model, Groq for enhanced AI performance and Streamlit for a seamless web interface. The chatbot can answer user queries, remember chat contexts, take and manage bookings.\nğŸ¥ Watch the demo video ğŸ”— Check out the application on Streamlit Cloud Background In the ever-evolving world of artificial intelligence, the advent of open-source Large Language Models (LLMs) like DCLM and Llama 3.1 has been looked at as a game-changer. But without real-world application, a good technology is like a work of art, valuable but not tangible.\nFor the past few days, I\u0026rsquo;ve been contemplating how we can harness these powerful tools. Coincidentally, while planning a weekend getaway, I found myself booking a hotel room through a WhatsApp conversation with a human receptionist. This got me thinking: can we use an LLM to handle bookings just as effectively? It seemed like a long shot, but I decided to give it a try.\nDiscovering the Tools: Groq and Streamlit During my research, I came across Groq and Streamlit:\nGroq: Imagine a super-efficient engine designed to accelerate machine learning models. Groq\u0026rsquo;s hardware and software solutions enhance the performance of AI applications, making them faster and more reliable. [ https://groq.com/ ] Streamlit: Think of Streamlit as a magic wand that turns your data scripts into shareable web apps. It\u0026rsquo;s a framework that allows you to create interactive websites from simple Python scripts, making data insights accessible and engaging. And streamlit-cloud makes the hosting a breeze. [ https://streamlit.io/ ] Building the Chatbot With these tools in hand and a little help from ChatGPT, I embarked on creating a chatbot to assist users with hotel bookings.\nThe Flow of the Code:\nHotel Information in JSON: The hotel details, including room types, prices, availability, and amenities, are structured in a JSON format. This ensures that the data is easily accessible and manageable. Passing Context to the LLM: This JSON data is passed as context to the LLM model (\u0026ldquo;llama-3.1-8b-instant\u0026rdquo;) via the Groq API, enabling the chatbot to respond with accurate and relevant information. Maintaining Chat Sessions: Consecutive chats in the session are also passed to the Groq API, ensuring that the bot remembers the flow of the conversation and maintains context throughout the interaction. Streamlit as the FrontEnd: used streamlit to provide a forntend to the interaction happening in the chat ğŸ‘‰ Check out the code in GitHub Where can it lead to? Dynamic Data Integration: While I used static information, the system can easily be adapted to pull live data from various sources, keeping the chatbot updated with current prices and availability. WhatsApp, Call? why not: Although I hosted the application on Streamlit, we can scale it, manage webhooks with ngrok , integrate it with platforms like Twilio to manage WhatsApp/SMS/Call interactions, or use text-to-speech AIs like vapi.ai for real-time conversations. Automated Booking Management: The chatbot can update booking information in a database, send confirmation emails to users, and remember past contexts from sessions to handle any follow-up queries seamlessly. Potential Use Cases: The applications of this technology extend far beyond the hospitality industry. Here are a few exciting possibilities:\nHealthcare: Streamlining patient appointments and managing inquiries. Retail: Assisting customers with product searches and order placements. Finance: Providing customer support for banking services and loan applications. Education: Facilitating enrollment processes and answering student queries. The Advantages of LLM based chat bots: The chatbot will respond naturally, so users won\u0026rsquo;t feel like they\u0026rsquo;re talking to a bot or navigating an IVR system. The user won\u0026rsquo;t be prompted to select one from the below options. The LLM can adapt to the conversation and provide personalized responses each time, enhancing the user experience. We don\u0026rsquo;t need to have huge set of data/ sample interactions to train the chatbots. Though they certainly be beneficial, but we can start fast, reducing the time to market. The bot can be provided with basic context and data, and it would perform quite well. This wouldn\u0026rsquo;t have been possible without this open sourced LLMs. Technologies Used: LLM, Groq API, Streamlit\nğŸ”— GitHub ğŸ“ Article ğŸ“± App Link ","permalink":"https://dibyendupm.netlify.app/projects/llm-driven-hotel-booking-chatbot/","summary":"Real-time conversational booking assistant powered by Groq API and Streamlit.","title":"LLM-Driven Hotel Booking Chatbot"},{"content":"Introduction In the bustling urban landscape, efficient traffic management is crucial for the smooth functioning of cities. Traffic signal control plays a pivotal role in regulating the flow of vehicles at intersections, ensuring safety, and minimizing congestion. To address the complexities of traffic signal coordination, I introduce a web application that empowers traffic engineers and city planners to optimize signal durations based on real-time traffic flow data.\nProblem Statement Traditional traffic signal systems often operate on fixed schedules, neglecting the dynamic nature of traffic patterns. This rigidity can lead to unnecessary delays, increased fuel consumption, and heightened environmental impact. Furthermore, the lack of tools to easily customize signal durations for specific intersections and traffic conditions poses a challenge for traffic management authorities.\nSolution This web application provides a comprehensive solution to the aforementioned challenges, offering a user-friendly interface and advanced functionalities. The system allows users to define and customize traffic signal timings at a granular level, considering the number of directions, specific coordinates for each direction, and real-time traffic flow data. (This is a personal project)\nProduct Features 1. Interactive Map Selection Users can select the location of a traffic signal crossing with the help of an interactive Bing Map interface. 2. Direction Input The application guides users through the process of inputting the number of directions traffic flows across the crossing.\nEach direction is uniquely identified, allowing for precise customization.\n3. Coordinate Mapping For each direction, users can easily input \u0026ldquo;from\u0026rdquo; and \u0026ldquo;to\u0026rdquo; coordinates by selecting points on the map.\nThis feature streamlines the process of defining the geographic scope of each traffic flow.\n4. Cycle Time Configuration Users can set the total cycle time for the traffic signal, offering flexibility in adjusting the overall timing based on specific requirements.\nThe default cycle time is calculated as \u0026rsquo;number of directions\u0026rsquo; times 90 seconds, providing a starting point for customization.\n5. Dynamic Traffic Flow Calculation The system integrates with bing API to fetch real-time traffic flow data between specified coordinates.\nThis data is used to dynamically calculate signal durations for each direction.\n6. Result Display The application presents the calculated signal durations in a clear and concise tabular format.\nUsers can easily interpret and implement the recommended signal timings for optimized traffic management.\nConclusion This Traffic Signal Control web application serves as a foundational step towards transforming traffic management in urban environments. While the current system empowers users to optimize signal durations at a specific intersection, its potential for scalability is a key aspect that can revolutionize citywide traffic flow.\nExtending the System to Configure Citywide Traffic Lights As cities evolve, the need for comprehensive traffic management systems becomes paramount. The simplicity and effectiveness of our web application pave the way for scaling the system to configure all traffic lights within a city. By expanding the tool\u0026rsquo;s capabilities to encompass multiple intersections, city planners and traffic engineers can holistically address traffic challenges on a macro level.\nAutomated Updates for Enhanced Efficiency Furthermore, envisioning a future where this system integrates with real-time traffic data and machine learning algorithms allows for automated updates. By leveraging data-driven insights, the system can continuously learn and adapt, reducing the reliance on manual interventions. This not only optimizes traffic flow but also enhances the overall efficiency of the transportation infrastructure.\nAdvantages of Reduced Human Intervention The automation of traffic signal configurations for an entire city comes with several advantages. It minimizes the risk of human error, ensures consistency in traffic management strategies, and allows for quicker responses to changing traffic patterns. Reduced human intervention translates to improved reliability and responsiveness, ultimately resulting in smoother traffic flow and reduced congestion.\nğŸ“± App Link ","permalink":"https://dibyendupm.netlify.app/projects/automated-traffic-signal-duration-simulator/","summary":"Simulates optimal signal durations using real-time Bing Maps traffic data.","title":"Automated Traffic Signal Duration Simulator"},{"content":"This application simulates the planning of delivery routes for a specified number of locations and delivery agents within Bangalore. The algorithm used is the Vehicle Routing Problem (VRP) solver provided byÂ OR-Tools , an optimization library developed by Google.\nAlgorithm The Vehicle Routing Problem (VRP) is a combinatorial optimization and integer programming problem that seeks to service a number of customers with a fleet of vehicles. It is a generalization of the Traveling Salesman Problem (TSP).\nStep 1:Â Generate a warehouse location and random delivery locations within Bangalore. Step 2:Â Use OR-Tools to solve the VRP with the specified number of delivery agents to minimize the total distance traveled. Step 3:Â Display the routes for each delivery agent on the map and show the total distance traveled. The algorithm ensures that the delivery routes are optimized for minimal travel distance, taking into account the constraints of the VRP.\nKey Features\nUses Google OR-Tools for path optimization Balances workloads and reduces total delivery time Generates interactive route visualizations Technologies Used: OR-Tools, Python, Streamlit\nğŸ”— GitHub ğŸ“± App Link ","permalink":"https://dibyendupm.netlify.app/projects/delivery-route-optimization/","summary":"Optimizes last-mile delivery routes using OR-Tools and Streamlit.","title":"Delivery Route Optimization"},{"content":"Introducing â€˜Product Management Interview Simulatorâ€™ - A Custom GPT In case you want to skip everything and try the simulator:\nPM interview simulator Practice makes perfect, and nowhere is this truer than in the realm of interviews. The more you practice, read, and learn, the more adept you become. For those preparing for product management interviews at junior and assistant levels, two books often come highly recommended:Â Cracking the PM InterviewÂ andÂ Decode and Conquer. These books are celebrated for their conversational examples between interviewers and candidates, which help readers grasp the interview dynamics effectively. With the advent of powerful tools like ChatGPT, one would expect interview preparation to be easier.Â Why did I create this?Â While preparing for PM interviews, we noticed that the responses from general GPTs often lacked the realistic flow and format expected by interviewers. So, we decided to create a solution that bridges this gap, helping you practice effectively and confidently.\nLet\u0026rsquo;s try out the most popular vanilla GPTs with a generic design questionÂ Design an alarm clock for the blind\nHere is the response fromÂ ChatGPT-4o. And hereâ€™s the same question posted toÂ Claude:Â Let\u0026rsquo;s try one more, this time an RCA question\nOla is experiencing a 25% decrease in daily ride bookings. How would you identify the root cause of this decline and propose solutions?\nLet\u0026rsquo;s see how chatgpt performs And here\u0026rsquo;s how Claude performs Though these are valuable insights, but not exactly how the interviewer expects the answer structure. Let\u0026rsquo;s try toÂ prompt to act as a PM interview candidateÂ and answer the question.\nItâ€™s clear that the responses are quite generic, lacking the structured and realistic flow expected in an actual interview.\nBridging the Gap: Introducing the â€˜Product Management Interview Simulatorâ€™ To address this gap, I created a custom GPT tailored specifically to help PM aspirants prepare for interviews. Iâ€™ve named it theÂ â€˜Product Management Interview Simulatorâ€™.Â Letâ€™s see how the custom GPT handles the same questions:Â What to expect?\nDetailed and Structured Responses:Â Get answers that follow the proper format, including clarifying questions and realistic scenarios enacting the interviewer and the interviewee.\nThe Design Question If you have ever prepared for PM interviews, this response looks much more realistic and acceptable right?\nThe RCA Question As you can see, this simulator closely mimics real-world scenarios, asking clarifying questions and following a proper flow and format.\nHow Did I Train the GPT? Creating this custom GPT involved leveraging ChatGPTâ€™s capabilities for training with prompts and custom data. For the training data, I scraped a wealth of mock interviews from various sources:\nPDFs of relevant books\nTranscripts of YouTube videos\nPosts from product management communities\nBlogs dedicated to PM topics\nI then cleaned and structured this data into a JSON format, a snippet as below:\nThe JSON file includes the question, related product, product type, question keyword, question type, and a detailed interaction between the interviewer and interviewee.\nFocus Areas I initially focused on five key question types, which are commonly asked for in PM interviews\nProduct Design\nRoot Cause Analysis (RCA)\nProblem Solving\nProduct Improvement\nProduct Metrics\nBy providing detailed context and employing few-shot prompting techniques, I configured the GPT to understand and format responses appropriately for the approach to different types of questions.\nYour Feedback Matters to Me While the GPT is still a work in progress, I am eager for feedback from the Product Management Community.Â If youâ€™re interested, please visit the custom GPT, try it out with different types of questions [out of the question-types mentioned above], and share your thoughts.\nHere is the link to the custom GPT:\nPM Interview Simulator Your input will not only help improve the tool but also help to reach fellow PM aspirants in their journey towards acing their interviews. Happy practicing!\nFeedback Your feedback (whether in my inbox, comments, or through a rating) will be immensely valuable.\nYou can click on the down arrow beside the GPT name on top left, and click onÂ \u0026lsquo;Review GPT\u0026rsquo;Â to post a ratingÂ Though you need to be a premium member to rate, however you just need to login to ChatGPT to use the simulator.\nDisclaimer These are LLMs and they can make mistake. They are not a replacement of creative, cognitive. logical and strategic thinking. The responses should only be taken as food for thought while practicing and exploring different types of questions.\n","permalink":"https://dibyendupm.netlify.app/projects/product-manager-interview-simulator/","summary":"Custom GPT model simulating realistic product management interviews.","title":"Interview Simulator"}]